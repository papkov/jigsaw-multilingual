{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /gpfs/hpc/home/papkov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "use cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as D\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('../src')\n",
    "import dataset\n",
    "import trainer\n",
    "import models\n",
    "import utils\n",
    "import preprocessing\n",
    "\n",
    "# Transformers\n",
    "import transformers\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer, XLMRobertaConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "\n",
    "# Setup device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Seed \n",
    "utils.seed_everything()\n",
    "\n",
    "print('use', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '../src/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 43.2 ms, total: 188 ms\n",
      "Wall time: 261 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8000, 512), (8000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "if debug:\n",
    "    valid = dataset.Dataset('../input/validatio_debug_32.npz')\n",
    "else:\n",
    "    valid = dataset.Dataset('../input/validation.npz')\n",
    "valid.x.shape, valid.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 731 ms, sys: 205 ms, total: 936 ms\n",
      "Wall time: 1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((63812, 512), (63812,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "if debug:\n",
    "    test = dataset.Dataset('../input/test_debug_32.npz')\n",
    "else:\n",
    "    test = dataset.Dataset('../input/test.npz')\n",
    "test.x.shape, test.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 700 ms, total: 2.84 s\n",
      "Wall time: 2.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((223549, 512), (223549,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "if debug:\n",
    "    train = dataset.Dataset('../input/jigsaw-toxic-comment-trai_debug_32.npz')\n",
    "else:\n",
    "    train = dataset.Dataset('../input/jigsaw-toxic-comment-train.npz')\n",
    "train.x.shape, train.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '../src/models.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = XLMRobertaModel(XLMRobertaConfig.from_pretrained('xlm-roberta-large'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn of regularization to make debugging easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload the module and not overload gpu\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Model(backbone, mix=False, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(backbone, mix=True, dropout=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /gpfs/hpc/home/papkov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from '../src/preprocessing.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature extraction: 100%|##########| 63/63 [04:35<00:00,  4.38s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing.extract_roberta_features_to_file('../input/validation.npz', backbone=backbone, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature extraction:  30%|###       | 152/499 [11:12<25:35,  4.43s/it]"
     ]
    }
   ],
   "source": [
    "preprocessing.extract_roberta_features_to_file('../input/test.npz', backbone=backbone, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.extract_roberta_features_to_file('../input/jigsaw-toxic-comment-train.npz', backbone=backbone, device=device, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers = 4\n",
    "\n",
    "loader_train = D.DataLoader(train, \n",
    "                            sampler=train.weighted_sampler(), \n",
    "                            batch_size=batch_size, num_workers=num_workers)\n",
    "loader_valid = D.DataLoader(valid, \n",
    "                            batch_size=batch_size, num_workers=num_workers)\n",
    "loader_test = D.DataLoader(test, \n",
    "                           batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21384, 4000, 31906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader_train), len(loader_valid), len(loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trainer' from '../src/trainer.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may optimize only head (with encoder pretrained)\n",
    "optimizer = AdamW(model.head.parameters(), lr=1e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnr = trainer.Trainer('base', model, \n",
    "                       loader_train, loader_valid, loader_test,\n",
    "                       epochs=5,\n",
    "                       monitor='val_loss',\n",
    "                       optimizer=optimizer,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y, am = next(iter(loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out, loss = trnr(x, y, am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0928, 1.2950],\n",
       "        [0.8992, 1.2395],\n",
       "        [1.1048, 1.3800],\n",
       "        [1.1402, 1.3978]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep. 0000 (lr 1.00e-04): 100%|##########| 16/16 [00:03<00:00,  4.20it/s, loss=0.556, acc=0.781]\n",
      "valid: 100%|##########| 16/16 [00:01<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete. val loss (avg): 0.5137, val acc: 0.8125\n",
      "Saved model to ../checkpoints//base_last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep. 0001 (lr 8.18e-05): 100%|##########| 16/16 [00:03<00:00,  4.24it/s, loss=0.311, acc=0.906]\n",
      "valid: 100%|##########| 16/16 [00:01<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. val loss (avg): 0.4835, val acc: 0.8125\n",
      "Saved model to ../checkpoints//base.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep. 0002 (lr 4.74e-05): 100%|##########| 16/16 [00:03<00:00,  4.22it/s, loss=0.29, acc=0.906] \n",
      "valid: 100%|##########| 16/16 [00:01<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete. val loss (avg): 0.4961, val acc: 0.8125\n",
      "Saved model to ../checkpoints//base_last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep. 0003 (lr 1.82e-05): 100%|##########| 16/16 [00:03<00:00,  4.22it/s, loss=0.325, acc=0.906]\n",
      "valid: 100%|##########| 16/16 [00:01<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete. val loss (avg): 0.5018, val acc: 0.8125\n",
      "Saved model to ../checkpoints//base_last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep. 0004 (lr 2.64e-06): 100%|##########| 16/16 [00:03<00:00,  4.22it/s, loss=0.314, acc=0.906]\n",
      "valid: 100%|##########| 16/16 [00:01<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete. val loss (avg): 0.5025, val acc: 0.8125\n",
      "Saved model to ../checkpoints//base_last.pth\n"
     ]
    }
   ],
   "source": [
    "trnr.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|##########| 4000/4000 [04:53<00:00, 13.63it/s]\n"
     ]
    }
   ],
   "source": [
    "pred, loss, acc = trnr.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|##########| 31906/31906 [38:58<00:00, 13.65it/s]\n"
     ]
    }
   ],
   "source": [
    "pred, loss, acc = trnr.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.320265071657932"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peenv (conda)",
   "language": "python",
   "name": "peenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
