{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/novin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "WARNING:__main__:Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "XLMRoberta Conditional Masked LM Instantiation.\n",
      "Conditional LM Head Instantiation.\n",
      "<class 'generation_models.RobertaConditionalLMHead'>\n",
      "Tokenize: 100%|███████████████████████████████| 86/86 [00:00<00:00, 1832.57it/s]\n",
      "Tokenize: 100%|███████████████████████████████| 15/15 [00:00<00:00, 2968.09it/s]\n",
      "Epoch:   0%|                                              | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                         | 0/11 [00:00<?, ?it/s]\u001b[A/opt/conda/conda-bld/pytorch_1587428111115/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcdiv_ is deprecated:\n",
      "\taddcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcdiv_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "\n",
      "Iteration:   9%|███                              | 1/11 [00:20<03:21, 20.19s/it]\u001b[A\n",
      "Evaluation: 100%|█████████████████████████████████| 2/2 [00:06<00:00,  4.13s/it]\n",
      "{\"eval_loss\": 12.565622329711914, \"epoch\": 0.18181818181818182, \"step\": 2}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE=\"../input/jigsaw-toxic-train-4generation-train.pkl\"\n",
    "TEST_FILE=\"../input/jigsaw-toxic-train-4generation-test.pkl\"\n",
    "\n",
    "# !export NPY_MKL_FORCE_INTEL=1\n",
    "!python ../src/train_lm.py \\\n",
    "    --output_dir=../outputs/output_xlm_roberta \\\n",
    "    --model_type=xlm-roberta \\\n",
    "    --model_name_or_path=xlm-roberta-base \\\n",
    "    --do_train \\\n",
    "    --train_data_file={TRAIN_FILE} \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file={TEST_FILE} \\\n",
    "    --mlm \\\n",
    "    --max_steps=1 \\\n",
    "    --overwrite_cache \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basenv]",
   "language": "python",
   "name": "conda-env-basenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
